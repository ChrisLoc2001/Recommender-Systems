{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dca357",
   "metadata": {},
   "source": [
    "# Local C.F. with cold Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e48efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d4455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di utenti attivi (almeno 20 valutazioni): 943 (total: 943)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "ratings_df = pd.read_csv('../datasets/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "ratings_df.drop(columns='timestamp', inplace=True)\n",
    "\n",
    "# Conta il numero di rating per ogni utente\n",
    "user_rating_counts = ratings_df['user_id'].value_counts()\n",
    "\n",
    "# Tieni solo gli utenti con almeno 20 valutazioni\n",
    "active_users = user_rating_counts[user_rating_counts >= 20].index\n",
    "\n",
    "# Filtra il dataset originale\n",
    "filtered_df = ratings_df[ratings_df['user_id'].isin(active_users)]\n",
    "print(f\"Numero di utenti attivi (almeno 20 valutazioni): {len(active_users)} (total: {len(ratings_df['user_id'].unique())})\")\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8570d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutti users presenti in rating_df e users_df: True\n",
      "Utenti: 943 Rating: 100000\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv('../datasets/ml-100k/u.user', sep='|', header=None, names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])\n",
    "all_in = users_df['user_id'].isin(ratings_df['user_id']).all()\n",
    "print(\"Tutti users presenti in rating_df e users_df:\", all_in)\n",
    "print(\"Utenti:\", len(users_df), \"Rating:\", len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90237750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "ratings_train, ratings_test = train_test_split(ratings_df, test_size=0.3, random_state=42)\n",
    "ratings_train = pd.DataFrame(ratings_train, columns=['user_id', 'movie_id', 'rating'])\n",
    "ratings_test = pd.DataFrame(ratings_test, columns=['user_id', 'movie_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f2f496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utenti cold start selezionati: [932 634 598 435 758 763 929  72 938 921 610 329 381 729 282]\n",
      "Utenti nel training: 928\n",
      "Utenti nel test: 943\n",
      "Cold start users nel training? False\n",
      "Cold start users nel test: True\n"
     ]
    }
   ],
   "source": [
    "# Scegli 5 utenti attivi da usare come cold start\n",
    "np.random.seed(42)  # per riproducibilità\n",
    "cold_start_users = np.random.choice(active_users, size=15, replace=False)\n",
    "print(f\"Utenti cold start selezionati: {cold_start_users}\")\n",
    "\n",
    "# Separa le valutazioni dei cold start users\n",
    "ratings_cold_users = filtered_df[filtered_df['user_id'].isin(cold_start_users)]\n",
    "\n",
    "# Resto del dataset (senza i cold start users)\n",
    "rest_df = filtered_df[~filtered_df['user_id'].isin(cold_start_users)]\n",
    "\n",
    "# Split 70/30 sul resto del dataset\n",
    "rest_train, rest_test = train_test_split(rest_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Costruzione dei set finali\n",
    "ratings_train = rest_train.copy()\n",
    "ratings_test = pd.concat([rest_test, ratings_cold_users], ignore_index=True)\n",
    "\n",
    "# Controlli\n",
    "print(\"Utenti nel training:\", ratings_train['user_id'].nunique())\n",
    "print(\"Utenti nel test:\", ratings_test['user_id'].nunique())\n",
    "print(\"Cold start users nel training?\", any(u in ratings_train['user_id'].values for u in cold_start_users))\n",
    "print(\"Cold start users nel test:\", all(u in ratings_test['user_id'].values for u in cold_start_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b968b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                               ...   \n",
       "1          5.0   3.0   NaN   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
       "user_id                                                               \n",
       "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1626 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "rating_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a20649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepara “sentences” per Word2Vec includendo anche zip_code\n",
    "sentences = users_df[['gender', 'occupation', 'zip_code']].astype(str).values.tolist()\n",
    "\n",
    "# 3. Allena il modello Word2Vec\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=8,    # dimensione del vettore di embedding\n",
    "    window=2,\n",
    "    min_count=1,\n",
    "    epochs=100,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# 4. Definisci funzione per calcolare embedding medio per riga\n",
    "def embed_row(row):\n",
    "    vecs = [w2v.wv[row['gender']], \n",
    "            w2v.wv[row['occupation']], \n",
    "            w2v.wv[row['zip_code']]]\n",
    "    # media vettoriale\n",
    "    return sum(vecs) / len(vecs)\n",
    "\n",
    "# 5. Applica embedding a tutto il DataFrame\n",
    "embeddings = users_df.apply(embed_row, axis=1)\n",
    "df_emb = pd.DataFrame(\n",
    "    embeddings.tolist(),\n",
    "    columns=[f'emb_{i}' for i in range(w2v.vector_size)]\n",
    ")\n",
    "# Aggiungiamo eventualmente altre feature numeriche (es. age)\n",
    "df_emb['age'] = users_df['age']\n",
    "\n",
    "# 6. Clustering sui vettori di embedding\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "users_df['cluster'] = kmeans.fit_predict(df_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23580004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice di similarita per utenti dello stesso cluster\n",
    "\n",
    "def create_similarity_matrix_local(rating_matrix, users_df, cluster_label, similarity='cosine'):\n",
    "\n",
    "    # Estrai gli ID utenti nel cluster\n",
    "    cluster_user_ids = users_df.loc[users_df['cluster'] == cluster_label, 'user_id']\n",
    "    \n",
    "    # Sottocampiona la matrice di rating solo per quegli utenti\n",
    "    R_cluster = rating_matrix.loc[rating_matrix.index.intersection(cluster_user_ids)]\n",
    "\n",
    "    # Centra i voti rispetto alla media utente\n",
    "    R_centered = R_cluster.sub(R_cluster.mean(axis=1), axis=0).fillna(0)\n",
    "\n",
    "    # Calcola la similarità\n",
    "    if similarity == \"pearson\":\n",
    "        similarity_matrix = 1 - pairwise_distances(R_centered, metric=\"correlation\")\n",
    "    elif similarity == \"cosine\":\n",
    "        similarity_matrix = cosine_similarity(R_centered)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported similarity metric. Use 'pearson' or 'cosine'.\")\n",
    "\n",
    "    return pd.DataFrame(similarity_matrix, index=R_cluster.index, columns=R_cluster.index)\n",
    "\n",
    "\n",
    "def predict_cluster_ratings(rating_matrix, users_df, cluster_label, similarity='cosine'):\n",
    "\n",
    "    # 1. Estrai la sotto-matrice di rating e la matrice di similarità locale\n",
    "    cluster_user_ids = users_df.loc[users_df['cluster'] == cluster_label, 'user_id']\n",
    "    R_cluster = rating_matrix.loc[rating_matrix.index.intersection(cluster_user_ids)]\n",
    "\n",
    "    if R_cluster.shape[0] < 2:\n",
    "        return pd.DataFrame(index=cluster_user_ids, columns=rating_matrix.columns)\n",
    "\n",
    "    # 2. Crea la matrice di similarità\n",
    "    similarity_matrix = create_similarity_matrix_local(rating_matrix, users_df, cluster_label, similarity)\n",
    "\n",
    "    # 3. Predizioni user-based sul cluster\n",
    "    user_means = R_cluster.replace(0, np.nan).mean(axis=1)\n",
    "    user_centered = R_cluster.sub(user_means, axis=0).fillna(0)\n",
    "\n",
    "    numerator_user = similarity_matrix.dot(user_centered)\n",
    "    denominator_user = np.abs(similarity_matrix).sum(axis=1)\n",
    "\n",
    "    prediction_matrix = numerator_user.div(denominator_user, axis=0).add(user_means, axis=0)\n",
    "    prediction_matrix = prediction_matrix.map(lambda x: 0 if x < 0.5 else 5 if x >= 5.5 else math.floor(x + 0.5))\n",
    "\n",
    "    return prediction_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5e7f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "1            4     3     4     4     4     4     4     3     4     4  ...   \n",
      "3            3     3     3     3     3     3     3     3     3     3  ...   \n",
      "4            4     4     4     4     4     4     4     4     4     4  ...   \n",
      "16           5     4     4     4     4     4     5     4     4     4  ...   \n",
      "22           3     3     3     3     3     3     3     3     3     3  ...   \n",
      "\n",
      "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "1            4     4     4     4     4     4     4     4     4     4  \n",
      "3            3     3     3     3     3     3     3     3     3     3  \n",
      "4            4     4     4     4     4     4     4     4     4     4  \n",
      "16           4     4     4     4     4     4     4     4     4     4  \n",
      "22           3     3     3     3     3     3     3     3     3     3  \n",
      "\n",
      "[5 rows x 1626 columns]\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "2            4     4     4     4     4     4     4     4     4     3  ...   \n",
      "7            4     4     4     4     4     4     4     4     4     4  ...   \n",
      "10           4     4     4     4     4     4     4     4     4     4  ...   \n",
      "47           3     3     3     3     4     4     4     4     4     3  ...   \n",
      "65           4     4     4     4     4     4     3     4     4     4  ...   \n",
      "\n",
      "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "2            4     4     4     4     4     4     4     4     4     4  \n",
      "7            4     4     4     4     4     4     4     4     4     4  \n",
      "10           4     4     4     4     4     4     4     4     4     4  \n",
      "47           4     4     4     4     4     4     4     4     4     4  \n",
      "65           4     4     4     4     4     4     4     4     4     4  \n",
      "\n",
      "[5 rows x 1626 columns]\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "5            3     3     3     3     3     3     3     3     3     3  ...   \n",
      "8            4     4     4     4     4     4     4     4     4     4  ...   \n",
      "9            4     4     4     4     4     4     4     4     4     4  ...   \n",
      "12           5     5     4     5     4     5     4     5     4     5  ...   \n",
      "17           3     3     3     3     3     3     3     3     3     3  ...   \n",
      "\n",
      "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "5            3     3     3     3     3     3     3     3     3     3  \n",
      "8            4     4     4     4     4     4     4     4     4     4  \n",
      "9            4     4     4     4     4     4     4     4     4     4  \n",
      "12           5     5     5     5     5     4     5     5     4     5  \n",
      "17           3     3     3     3     3     3     3     3     3     3  \n",
      "\n",
      "[5 rows x 1626 columns]\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "6            4     4     4     4     4     4     4     4     4     4  ...   \n",
      "11           3     3     3     3     3     3     4     4     4     3  ...   \n",
      "13           3     3     3     3     3     3     3     3     3     3  ...   \n",
      "14           4     4     4     4     4     4     4     4     4     4  ...   \n",
      "15           3     3     3     3     3     3     3     3     3     3  ...   \n",
      "\n",
      "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "6            4     4     4     4     4     4     4     4     4     4  \n",
      "11           3     3     3     3     3     3     3     3     3     3  \n",
      "13           3     3     3     3     3     3     3     3     3     3  \n",
      "14           4     4     4     4     4     4     4     4     4     4  \n",
      "15           3     3     3     3     3     3     3     3     3     3  \n",
      "\n",
      "[5 rows x 1626 columns]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "\n",
    "for label in users_df['cluster'].unique():\n",
    "    pred = predict_cluster_ratings(rating_matrix, users_df, cluster_label=label, similarity='cosine')\n",
    "    print(pred.head())\n",
    "    all_predictions.append(pred)\n",
    "\n",
    "# Ricostruzione della matrice predizioni globale\n",
    "final_prediction_matrix = pd.concat(all_predictions)\n",
    "final_prediction_matrix = final_prediction_matrix.sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179e1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_user_ratings_clustered(rating_matrix, users_df, similarity='cosine'):\n",
    "    \n",
    "    # --- STEP 1: Predizioni per utenti noti ---\n",
    "    all_predictions = []\n",
    "    for label in users_df['cluster'].unique():\n",
    "        pred = predict_cluster_ratings(rating_matrix, users_df, cluster_label=label, similarity=similarity)\n",
    "        all_predictions.append(pred)\n",
    "\n",
    "    final_prediction_matrix = pd.concat(all_predictions)\n",
    "    final_prediction_matrix = final_prediction_matrix.sort_index()\n",
    "    known_users = set(final_prediction_matrix.index)\n",
    "\n",
    "    # --- STEP 2: Predizioni per utenti cold-start ---\n",
    "    all_users = set(users_df['user_id'])\n",
    "    cold_start_users = list(all_users - known_users)\n",
    "    cold_preds = {}\n",
    "\n",
    "    for uid in cold_start_users:\n",
    "        cluster_row = users_df[users_df['user_id'] == uid]\n",
    "        if cluster_row.empty:\n",
    "            print(f\"Utente {uid} non trovato.\")\n",
    "            continue\n",
    "\n",
    "        cluster = cluster_row['cluster'].values[0]\n",
    "        cluster_user_ids = users_df[users_df['cluster'] == cluster]['user_id']\n",
    "        cluster_ratings = rating_matrix.loc[rating_matrix.index.intersection(cluster_user_ids)]\n",
    "\n",
    "        if cluster_ratings.empty:\n",
    "            print(f\"Cluster {cluster} vuoto per cold-start {uid}\")\n",
    "            continue\n",
    "\n",
    "        cold_preds[uid] = cluster_ratings.mean()\n",
    "\n",
    "    cold_df = pd.DataFrame.from_dict(cold_preds, orient='index')\n",
    "\n",
    "    # --- STEP 3: Unione ---\n",
    "    full_matrix = pd.concat([final_prediction_matrix, cold_df])\n",
    "    full_matrix = full_matrix.sort_index().reindex(columns=rating_matrix.columns).fillna(0)\n",
    "    full_matrix.index.name = 'user_id'\n",
    "\n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fdfb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_matrix = predict_all_user_ratings_clustered(rating_matrix, users_df, similarity='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff454cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id movie_id  predicted_rating\n",
      "0        1        1               4.0\n",
      "1        2        1               4.0\n",
      "2        3        1               3.0\n",
      "3        4        1               4.0\n",
      "4        5        1               3.0\n"
     ]
    }
   ],
   "source": [
    "prediction_df = pred_matrix.reset_index().melt(\n",
    "    id_vars='user_id', \n",
    "    var_name='movie_id', \n",
    "    value_name='predicted_rating'\n",
    ")\n",
    "print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6247b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ratings(ratings_test, prediction_df, thresholds=[3.0]):\n",
    "    # Unione dei dataframe test e predizioni\n",
    "    valutazione_df = ratings_test.merge(prediction_df, on=[\"user_id\", \"movie_id\"], how=\"inner\")\n",
    "\n",
    "    # Calcolo RMSE e MAE (rimangono invariati per tutte le soglie)\n",
    "    rmse = np.sqrt(mean_squared_error(valutazione_df[\"rating\"], valutazione_df[\"predicted_rating\"]))\n",
    "    mae = mean_absolute_error(valutazione_df[\"rating\"], valutazione_df[\"predicted_rating\"])\n",
    "\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Lista per salvare i risultati\n",
    "    risultati = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # Binarizzazione in base alla soglia\n",
    "        valutazione_df[\"true_label\"] = (valutazione_df[\"rating\"] >= threshold).astype(int)\n",
    "        valutazione_df[\"predicted_label\"] = (valutazione_df[\"predicted_rating\"] >= threshold).astype(int)\n",
    "\n",
    "        # Calcolo metriche di classificazione\n",
    "        accuracy = accuracy_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"])\n",
    "        precision = precision_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"], zero_division=0)\n",
    "        recall = recall_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"], zero_division=0)\n",
    "\n",
    "        # Stampa risultati\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(\"\")\n",
    "\n",
    "        # Salva risultati in lista\n",
    "        risultati.append({\n",
    "            \"threshold\": threshold,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(risultati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3bd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0499\n",
      "MAE: 0.7774\n",
      "\n",
      "Threshold: 2\n",
      "Accuracy: 0.9424\n",
      "Precision: 0.9437\n",
      "Recall: 0.9985\n",
      "\n",
      "Threshold: 3\n",
      "Accuracy: 0.8317\n",
      "Precision: 0.8392\n",
      "Recall: 0.9852\n",
      "\n",
      "Threshold: 4.0\n",
      "Accuracy: 0.6484\n",
      "Precision: 0.6841\n",
      "Recall: 0.6818\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.942362</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.998476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.831747</td>\n",
       "      <td>0.839239</td>\n",
       "      <td>0.985207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.648391</td>\n",
       "      <td>0.684071</td>\n",
       "      <td>0.681750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy  precision    recall\n",
       "0        2.0  0.942362   0.943651  0.998476\n",
       "1        3.0  0.831747   0.839239  0.985207\n",
       "2        4.0  0.648391   0.684071  0.681750"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [2, 3, 4.0]\n",
    "# Valutazione delle predizioni con le metriche di classificazione per la Similarità Coseno\n",
    "evaluate_ratings(ratings_test, prediction_df, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da02cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_ap_multi_k(ratings_test, prediction_df, k_values=[5], rel_thresholds=[4]):\n",
    "    # Unione dei dataframe test e predizioni\n",
    "    valutazione_df = ratings_test.merge(prediction_df, on=[\"user_id\", \"movie_id\"], how=\"inner\")\n",
    "    all_metrics = []\n",
    "\n",
    "    for rel_threshold in rel_thresholds:\n",
    "        for k in k_values:\n",
    "            for user_id, group in valutazione_df.groupby('user_id'):\n",
    "                # Ordinare per predicted_rating decrescente\n",
    "                group_sorted = group.sort_values('predicted_rating', ascending=False)\n",
    "\n",
    "                # Rilevanti reali (ground truth)\n",
    "                relevant_items = set(group[group['rating'] >= rel_threshold]['movie_id'])\n",
    "\n",
    "                # Top-k raccomandati\n",
    "                recommended = group_sorted.head(k)\n",
    "                recommended_ids = list(recommended['movie_id'])\n",
    "\n",
    "                # Precision@k\n",
    "                rel_k = [1 if movie in relevant_items else 0 for movie in recommended_ids]\n",
    "                precision_at_k = sum(rel_k) / k\n",
    "\n",
    "                # Recall@k\n",
    "                recall_at_k = sum(rel_k) / len(relevant_items) if relevant_items else 0.0\n",
    "\n",
    "                # Average Precision@k (AP@k)\n",
    "                num_hits = 0\n",
    "                sum_precisions = 0.0\n",
    "                for i, hit in enumerate(rel_k):\n",
    "                    if hit:\n",
    "                        num_hits += 1\n",
    "                        sum_precisions += num_hits / (i + 1)\n",
    "                ap_at_k = sum_precisions / len(relevant_items) if relevant_items else 0.0\n",
    "\n",
    "                all_metrics.append({\n",
    "                    'user_id': user_id,\n",
    "                    'k': k,\n",
    "                    'rel_threshold': rel_threshold,\n",
    "                    'precision@k': precision_at_k,\n",
    "                    'recall@k': recall_at_k,\n",
    "                    'ap@k': ap_at_k\n",
    "                })\n",
    "\n",
    "    # Tutti i risultati\n",
    "    results_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "    # MAP@k per ogni combinazione di k e soglia\n",
    "    mapk_summary = (\n",
    "        results_df.groupby(['k', 'rel_threshold'])['ap@k']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'ap@k': 'MAP@k'})\n",
    "    )\n",
    "\n",
    "    return results_df, mapk_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400efaa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m k_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m]\n\u001b[0;32m      2\u001b[0m threshold_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m risultati_utenti, mapk \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_ap_multi_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m risultati_utenti\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP@k per ogni combinazione di k e soglia:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mprecision_recall_ap_multi_k\u001b[1;34m(ratings_test, prediction_df, k_values, rel_thresholds)\u001b[0m\n\u001b[0;32m     10\u001b[0m group_sorted \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_rating\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Rilevanti reali (ground truth)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m relevant_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrel_threshold\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Top-k raccomandati\u001b[39;00m\n\u001b[0;32m     16\u001b[0m recommended \u001b[38;5;241m=\u001b[39m group_sorted\u001b[38;5;241m.\u001b[39mhead(k)\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\frame.py:4152\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4149\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m-> 4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6815\u001b[0m     )\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32md:\\Download\\Miniconda\\Anaconda\\envs\\FDSML\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_list = [5, 10, 15, 20]\n",
    "threshold_list = [3, 4]\n",
    "\n",
    "risultati_utenti, mapk = precision_recall_ap_multi_k(ratings_test, prediction_df, k_list, threshold_list)\n",
    "risultati_utenti.head()\n",
    "\n",
    "print(\"MAP@k per ogni combinazione di k e soglia:\")\n",
    "print(mapk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
