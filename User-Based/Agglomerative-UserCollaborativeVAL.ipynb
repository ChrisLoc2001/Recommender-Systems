{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb752a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815683ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ratings_by_user(rating_df, test_size=0.2):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    for user_id, group in rating_df.groupby('userId'):\n",
    "        if len(group) < 5:\n",
    "            continue  # ignora utenti con pochi rating\n",
    "\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=42)\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    return pd.concat(train_list), pd.concat(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef95ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 1000\n",
    "\n",
    "rating_df = pd.read_csv('../datasets/MovieDS/ratings.csv')\n",
    "rating_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "user_counts = rating_df['userId'].value_counts()\n",
    "active_users = user_counts[user_counts >= 20].index\n",
    "rating_df = rating_df[rating_df['userId'].isin(active_users)].copy()\n",
    "if len(active_users) > flag:\n",
    "    sampled_users = np.random.choice(active_users, flag, replace=False)\n",
    "    rating_df = rating_df[rating_df['userId'].isin(sampled_users)]\n",
    "\n",
    "\n",
    "rating_train, rating_test = split_ratings_by_user(rating_df=rating_df)\n",
    "\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = rating_train['userId'].unique()\n",
    "movie_ids = rating_train['movieId'].unique()\n",
    "\n",
    "user_mapper  = {uid: i for i, uid in enumerate(user_ids)}\n",
    "movie_mapper = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "\n",
    "user_idx  = rating_train['userId'] .map(user_mapper)\n",
    "movie_idx = rating_train['movieId'].map(movie_mapper)\n",
    "\n",
    "sparse_matrix = csr_matrix(\n",
    "    (rating_train['rating'], (user_idx, movie_idx)),\n",
    "    shape=(len(user_ids), len(movie_ids))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riduzione dimensionale\n",
    "normalizer = Normalizer()\n",
    "ratings_norm = normalizer.fit_transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01faef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "agglo = AgglomerativeClustering(\n",
    "    n_clusters=n_clusters,\n",
    "    linkage='ward'          # minimizza la varianza intra-cluster\n",
    ")\n",
    "# Agglomerative richiede input denso:\n",
    "user_clusters = agglo.fit_predict(ratings_norm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ba2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_user_mapper = {v: k for k, v in user_mapper.items()}\n",
    "cluster_df = pd.DataFrame({\n",
    "    'userId': [inv_user_mapper[i] for i in range(len(user_clusters))],\n",
    "    'cluster': user_clusters\n",
    "})\n",
    "rating_df = rating_df.merge(cluster_df, on='userId', how='left')\n",
    "\n",
    "print(\"Cluster assegnati:\", rating_df['cluster'].unique())\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items_df(user_id:int, rating_df: pd.DataFrame, top_n=5):\n",
    "    # Ottieni il cluster dell'utente\n",
    "    user_cluster = rating_df.loc[rating_df['userId'] == user_id, 'cluster'].iloc[0]\n",
    "    \n",
    "    # Film già valutati dall'utente\n",
    "    rated_movies = set(rating_df[rating_df['userId'] == user_id]['movieId'])\n",
    "    \n",
    "    # Filtra solo utenti nello stesso cluster, escludendo quelli già visti dall'utente\n",
    "    cluster_df: pd.DataFrame = rating_df[(rating_df['cluster'] == user_cluster) & (~rating_df['movieId'].isin(rated_movies))]\n",
    "    \n",
    "    # Calcola la media dei rating per ciascun film\n",
    "    movie_means = cluster_df.groupby('movieId')['rating'].mean()\n",
    "    \n",
    "    # Seleziona i top-N film con media più alta\n",
    "    top_movies = movie_means.sort_values(ascending=False).head(top_n)\n",
    "    \n",
    "    return top_movies.index.tolist()\n",
    "\n",
    "\n",
    "random_user = rating_df['userId'].drop_duplicates().sample(1).iloc[0]\n",
    "user_id = random_user\n",
    "\n",
    "recommended_ids = recommend_items_df(user_id=user_id, rating_df=rating_df)\n",
    "movies_df = pd.read_csv('../datasets/MovieDS/movies.csv')\n",
    "recommended_movies = movies_df[movies_df['movieId'].isin(recommended_ids)]\n",
    "recommended_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import List\n",
    "\n",
    "### STEP 1 – Caricamento dati\n",
    "rating_df = pd.read_csv('../datasets/MovieDS/ratings.csv')\n",
    "rating_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "user_counts = rating_df['userId'].value_counts()\n",
    "active_users = user_counts[user_counts >= 20].index\n",
    "rating_df = rating_df[rating_df['userId'].isin(active_users)].copy()\n",
    "if len(active_users) > flag:\n",
    "    sampled_users = np.random.choice(active_users, flag, replace=False)\n",
    "    rating_df = rating_df[rating_df['userId'].isin(sampled_users)]\n",
    "\n",
    "\n",
    "### STEP 2 – Train/test split per utente\n",
    "def split_ratings_by_user(rating_df: pd.DataFrame, test_size=0.2):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for user_id, group in rating_df.groupby('userId'):\n",
    "        if len(group) < 5:\n",
    "            continue\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=42)\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "    return pd.concat(train_list), pd.concat(test_list)\n",
    "\n",
    "rating_train, rating_test = split_ratings_by_user(rating_df)\n",
    "\n",
    "### STEP 3 – Clustering utenti nel training set\n",
    "def cluster_users(df: pd.DataFrame, n_clusters=5):\n",
    "    user_ids = df['userId'].unique()\n",
    "    movie_ids = df['movieId'].unique()\n",
    "\n",
    "    user_mapper  = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    movie_mapper = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "\n",
    "    user_idx  = df['userId'] .map(user_mapper)\n",
    "    movie_idx = df['movieId'].map(movie_mapper)\n",
    "\n",
    "    sparse_matrix = csr_matrix(\n",
    "        (df['rating'], (user_idx, movie_idx)),\n",
    "        shape=(len(user_ids), len(movie_ids))\n",
    "    )\n",
    "\n",
    "    normalizer = Normalizer()\n",
    "    ratings_norm = normalizer.fit_transform(sparse_matrix)\n",
    "\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42)\n",
    "    user_clusters = kmeans.fit_predict(ratings_norm)\n",
    "\n",
    "    inv_user_mapper = {v: k for k, v in user_mapper.items()}\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'userId': [inv_user_mapper[i] for i in range(len(user_clusters))],\n",
    "        'cluster': user_clusters\n",
    "    })\n",
    "\n",
    "    df = df.merge(cluster_df, on='userId', how='left')\n",
    "    return df\n",
    "\n",
    "rating_train = cluster_users(rating_train, n_clusters=5)\n",
    "\n",
    "### STEP 4 – Raccomandazione top-N dal cluster\n",
    "def recommend_items_df(user_id: int, rating_df: pd.DataFrame, top_n=5) -> List[int]:\n",
    "    if user_id not in rating_df['userId'].values:\n",
    "        return []\n",
    "    user_cluster = rating_df.loc[rating_df['userId'] == user_id, 'cluster'].iloc[0]\n",
    "    rated_movies = set(rating_df[rating_df['userId'] == user_id]['movieId'])\n",
    "    cluster_df = rating_df[(rating_df['cluster'] == user_cluster) & (~rating_df['movieId'].isin(rated_movies))]\n",
    "    movie_means = cluster_df.groupby('movieId')['rating'].mean()\n",
    "    top_movies = movie_means.sort_values(ascending=False).head(top_n)\n",
    "    return top_movies.index.tolist()\n",
    "\n",
    "### STEP 5 – Valutazione: Precision@N e Recall@N\n",
    "def evaluate_recommender(rating_train: pd.DataFrame, rating_test: pd.DataFrame, top_n=5, threshold=4.0):\n",
    "    users = rating_test['userId'].unique()\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for user_id in users:\n",
    "        if user_id not in rating_train['userId'].values:\n",
    "            continue\n",
    "\n",
    "        relevant_movies = set(\n",
    "            rating_test[(rating_test['userId'] == user_id) &\n",
    "                        (rating_test['rating'] >= threshold)]['movieId']\n",
    "        )\n",
    "        if not relevant_movies:\n",
    "            continue\n",
    "\n",
    "        recommended = recommend_items_df(user_id, rating_train, top_n)\n",
    "        if not recommended:\n",
    "            continue\n",
    "\n",
    "        recommended_set = set(recommended)\n",
    "        true_positives = recommended_set & relevant_movies\n",
    "\n",
    "        precision = len(true_positives) / len(recommended_set)\n",
    "        recall    = len(true_positives) / len(relevant_movies)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall    = np.mean(recalls)\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "### STEP 6 – Esegui la valutazione\n",
    "precision, recall = evaluate_recommender(rating_train, rating_test, top_n=5)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5:    {recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
