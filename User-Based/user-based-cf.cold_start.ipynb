{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e48efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d4455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di utenti attivi (almeno 20 valutazioni): 943 (total: 943)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "ratings_df = pd.read_csv('../datasets/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "ratings_df.drop(columns='timestamp', inplace=True)\n",
    "\n",
    "# Conta il numero di rating per ogni utente\n",
    "user_rating_counts = ratings_df['user_id'].value_counts()\n",
    "\n",
    "# Tieni solo gli utenti con almeno 20 valutazioni\n",
    "active_users = user_rating_counts[user_rating_counts >= 20].index\n",
    "\n",
    "# Filtra il dataset originale\n",
    "filtered_df = ratings_df[ratings_df['user_id'].isin(active_users)]\n",
    "print(f\"Numero di utenti attivi (almeno 20 valutazioni): {len(active_users)} (total: {len(ratings_df['user_id'].unique())})\")\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8570d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutti users presenti in rating_df e users_df: True\n",
      "Utenti: 943 Rating: 100000\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv('../datasets/ml-100k/u.user', sep='|', header=None, names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])\n",
    "all_in = users_df['user_id'].isin(ratings_df['user_id']).all()\n",
    "print(\"Tutti users presenti in rating_df e users_df:\", all_in)\n",
    "print(\"Utenti:\", len(users_df), \"Rating:\", len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90237750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "ratings_train, ratings_test = train_test_split(ratings_df, test_size=0.3, random_state=42)\n",
    "ratings_train = pd.DataFrame(ratings_train, columns=['user_id', 'movie_id', 'rating'])\n",
    "ratings_test = pd.DataFrame(ratings_test, columns=['user_id', 'movie_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f2f496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utenti cold start selezionati: [932 634 598 435 758 763 929  72 938 921 610 329 381 729 282]\n",
      "Utenti nel training: 928\n",
      "Utenti nel test: 943\n",
      "Cold start users nel training? False\n",
      "Cold start users nel test: True\n"
     ]
    }
   ],
   "source": [
    "# Scegli 5 utenti attivi da usare come cold start\n",
    "np.random.seed(42)  # per riproducibilità\n",
    "cold_start_users = np.random.choice(active_users, size=15, replace=False) # Size indica quanti utenti rimuovere\n",
    "print(f\"Utenti cold start selezionati: {cold_start_users}\")\n",
    "\n",
    "# Separa le valutazioni dei cold start users\n",
    "ratings_cold_users = filtered_df[filtered_df['user_id'].isin(cold_start_users)]\n",
    "\n",
    "# Resto del dataset (senza i cold start users)\n",
    "rest_df = filtered_df[~filtered_df['user_id'].isin(cold_start_users)]\n",
    "\n",
    "# Split 70/30 sul resto del dataset\n",
    "rest_train, rest_test = train_test_split(rest_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Costruzione dei set finali\n",
    "ratings_train = rest_train.copy()\n",
    "ratings_test = pd.concat([rest_test, ratings_cold_users], ignore_index=True)\n",
    "\n",
    "# Controlli\n",
    "print(\"Utenti nel training:\", ratings_train['user_id'].nunique())\n",
    "print(\"Utenti nel test:\", ratings_test['user_id'].nunique())\n",
    "print(\"Cold start users nel training?\", any(u in ratings_train['user_id'].values for u in cold_start_users))\n",
    "print(\"Cold start users nel test:\", all(u in ratings_test['user_id'].values for u in cold_start_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b968b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                               ...   \n",
       "1          5.0   3.0   NaN   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
       "user_id                                                               \n",
       "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1626 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "rating_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a20649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepara “sentences” per Word2Vec includendo anche zip_code\n",
    "sentences = users_df[['gender', 'occupation', 'zip_code']].astype(str).values.tolist()\n",
    "\n",
    "# 3. Allena il modello Word2Vec\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=8,    # dimensione del vettore di embedding\n",
    "    window=2,\n",
    "    min_count=1,\n",
    "    epochs=100,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# 4. Definisci funzione per calcolare embedding medio per riga\n",
    "def embed_row(row):\n",
    "    vecs = [w2v.wv[row['gender']], \n",
    "            w2v.wv[row['occupation']], \n",
    "            w2v.wv[row['zip_code']]]\n",
    "    # media vettoriale\n",
    "    return sum(vecs) / len(vecs)\n",
    "\n",
    "# 5. Applica embedding a tutto il DataFrame\n",
    "embeddings = users_df.apply(embed_row, axis=1)\n",
    "df_emb = pd.DataFrame(\n",
    "    embeddings.tolist(),\n",
    "    columns=[f'emb_{i}' for i in range(w2v.vector_size)]\n",
    ")\n",
    "# Aggiungiamo eventualmente altre feature numeriche (es. age)\n",
    "df_emb['age'] = users_df['age']\n",
    "\n",
    "# 6. Clustering sui vettori di embedding\n",
    "agg_final = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
    "users_df['cluster'] = agg_final.fit_predict(df_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23580004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix(rating_matrix, similarity: str):\n",
    "    \"\"\"\n",
    "    Crea una matrice di similarità tra gli utenti basata sulla metrica specificata.\n",
    "    \"\"\"\n",
    "    R_centered = rating_matrix.sub(rating_matrix.mean(axis=1), axis=0)\n",
    "    R_filled_user = R_centered.fillna(0)\n",
    "    if similarity == \"pearson\":   \n",
    "        similarity_matrix = 1 - pairwise_distances(R_filled_user, metric=\"correlation\")\n",
    "    elif similarity == \"cosine\":\n",
    "        similarity_matrix = cosine_similarity(R_filled_user)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported similarity metric. Use 'pearson' or 'cosine'.\")\n",
    "\n",
    "    return pd.DataFrame(similarity_matrix, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "\n",
    "def predict_ratings_user_based(rating_matrix, similarity):\n",
    "    \"\"\"\n",
    "    Calcola la matrice di predizione dei voti usando il Collaborative Filtering user-based.\n",
    "\n",
    "    Parametri:\n",
    "    - rating_matrix (DataFrame): matrice utenti-elementi con voti.\n",
    "    - similarity (str): metrica di similarità usata.\n",
    "\n",
    "    Ritorna:\n",
    "    - prediction_matrix (DataFrame): matrice dei voti predetti.\n",
    "    \"\"\"\n",
    "    \n",
    "    similarity_matrix = create_similarity_matrix(rating_matrix, similarity)\n",
    "\n",
    "    # 1. Calcola la media dei voti per ogni utente (ignorando gli zeri)\n",
    "    user_means = rating_matrix.replace(0, np.nan).mean(axis=1)\n",
    "\n",
    "    # 2. Calcola lo scarto di ogni voto rispetto alla media dell'utente\n",
    "    user_centered = rating_matrix.sub(user_means, axis=0).fillna(0)\n",
    "\n",
    "    # 3. Calcola il numeratore: prodotto scalare tra similarità e scarti\n",
    "    numerator_user = similarity_matrix.dot(user_centered)\n",
    "\n",
    "    # 4. Calcola il denominatore: somma dei valori assoluti delle similarità\n",
    "    denominator_user = np.abs(similarity_matrix).sum(axis=1)\n",
    "\n",
    "    # 5. Calcola la predizione aggiungendo la media utente e arrotondando\n",
    "    prediction_matrix = numerator_user.div(denominator_user, axis=0).add(user_means, axis=0)\n",
    "\n",
    "    # Applica soglia e arrotondamento\n",
    "    prediction_matrix = prediction_matrix.map(lambda x: 0 if x < 0.5 else 5 if x >= 5.5 else math.floor(x + 0.5))\n",
    "\n",
    "    return prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179e1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_user_ratings(rating_matrix, users_df, cold_start_users, similarity='cosine'):\n",
    "    \"\"\"\n",
    "    Predice i voti per tutti gli utenti:\n",
    "    - usa CF per utenti presenti nella matrice\n",
    "    - usa media del cluster per utenti cold-start\n",
    "\n",
    "    Params:\n",
    "    - rating_matrix: matrice utenti × film (train)\n",
    "    - users_df: DataFrame con metadati utente (deve avere 'user_id' e 'cluster')\n",
    "    - similarity: 'cosine' o 'pearson'\n",
    "    - kmeans: modello KMeans già addestrato\n",
    "    - df_emb: DataFrame con embeddings (usato per utenti cold-start)\n",
    "    - embed_row: funzione per calcolare embedding da una riga utente\n",
    "\n",
    "    Return:\n",
    "    - prediction_matrix: DataFrame user_id × movie_id con tutte le predizioni\n",
    "    \"\"\"\n",
    "    all_user_ids = users_df['user_id'].unique()\n",
    "    movie_ids = rating_matrix.columns\n",
    "\n",
    "    # 1. CF prediction for known users\n",
    "    cf_prediction = predict_ratings_user_based(rating_matrix, similarity)\n",
    "    predictions = {}\n",
    "\n",
    "    for uid in cf_prediction.index:\n",
    "        predictions[int(uid)] = cf_prediction.loc[uid]\n",
    "\n",
    "    # 2. Cluster-based prediction for cold start users\n",
    "    for uid in cold_start_users:\n",
    "        uid = int(uid)\n",
    "        cluster_row = users_df[users_df['user_id'] == uid]\n",
    "        if cluster_row.empty:\n",
    "            print(f\"Utente {uid} non trovato in users_df\")\n",
    "            continue\n",
    "\n",
    "        cluster = cluster_row['cluster'].values[0]\n",
    "        print(f\"Predizione per utente cold start: {uid}, cluster: {cluster}\")\n",
    "\n",
    "        cluster_user_ids = users_df[users_df['cluster'] == cluster]['user_id']\n",
    "        cluster_ratings = rating_matrix.loc[rating_matrix.index.intersection(cluster_user_ids)]\n",
    "\n",
    "        if cluster_ratings.empty:\n",
    "            print(f\"Cluster {cluster} per utente {uid} vuoto, fallback non implementato.\")\n",
    "            continue\n",
    "\n",
    "        mean_ratings = cluster_ratings.mean()\n",
    "        predictions[uid] = mean_ratings\n",
    "\n",
    "    # 3. Costruzione del DataFrame finale\n",
    "    prediction_matrix = pd.DataFrame.from_dict(predictions, orient='index')\n",
    "    prediction_matrix = prediction_matrix.reindex(columns=movie_ids)  # assicura che le colonne siano ordinate\n",
    "    prediction_matrix.index.name = 'user_id'\n",
    "\n",
    "    # 4. Pulizia finale\n",
    "    prediction_matrix = prediction_matrix.fillna(0)\n",
    "    return prediction_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdfb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizione per utente cold start: 932, cluster: 2\n",
      "Predizione per utente cold start: 634, cluster: 0\n",
      "Predizione per utente cold start: 598, cluster: 0\n",
      "Predizione per utente cold start: 435, cluster: 1\n",
      "Predizione per utente cold start: 758, cluster: 1\n",
      "Predizione per utente cold start: 763, cluster: 1\n",
      "Predizione per utente cold start: 929, cluster: 0\n",
      "Predizione per utente cold start: 72, cluster: 2\n",
      "Predizione per utente cold start: 938, cluster: 0\n",
      "Predizione per utente cold start: 921, cluster: 1\n",
      "Predizione per utente cold start: 610, cluster: 1\n",
      "Predizione per utente cold start: 329, cluster: 2\n",
      "Predizione per utente cold start: 381, cluster: 0\n",
      "Predizione per utente cold start: 729, cluster: 1\n",
      "Predizione per utente cold start: 282, cluster: 1\n",
      "Predizioni ((943, 1626)):\n",
      "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                               ...   \n",
      "1          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  ...   \n",
      "2          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  ...   \n",
      "3          3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0  ...   \n",
      "4          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  ...   \n",
      "5          3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0  ...   \n",
      "\n",
      "movie_id  1671  1672  1674  1675  1676  1677  1679  1680  1681  1682  \n",
      "user_id                                                               \n",
      "1          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  \n",
      "2          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  \n",
      "3          3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0  \n",
      "4          4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  \n",
      "5          3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0  \n",
      "\n",
      "[5 rows x 1626 columns]\n"
     ]
    }
   ],
   "source": [
    "prediction_df = predict_all_user_ratings(rating_matrix, users_df, cold_start_users, \"pearson\")\n",
    "\n",
    "# Visualizza le prime 5 righe della matrice di predizione\n",
    "print(f\"Predizioni ({prediction_df.shape}):\") \n",
    "print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff454cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id movie_id  predicted_rating\n",
      "0        1        1               4.0\n",
      "1        2        1               4.0\n",
      "2        3        1               3.0\n",
      "3        4        1               4.0\n",
      "4        5        1               3.0\n"
     ]
    }
   ],
   "source": [
    "prediction_df = prediction_df.reset_index().melt(id_vars='user_id', var_name='movie_id', value_name='predicted_rating')\n",
    "print(prediction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6247b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ratings(ratings_test, prediction_df, thresholds=[3.0]):\n",
    "    # Unione dei dataframe test e predizioni\n",
    "    valutazione_df = ratings_test.merge(prediction_df, on=[\"user_id\", \"movie_id\"], how=\"inner\")\n",
    "\n",
    "    # Calcolo RMSE e MAE (rimangono invariati per tutte le soglie)\n",
    "    rmse = np.sqrt(mean_squared_error(valutazione_df[\"rating\"], valutazione_df[\"predicted_rating\"]))\n",
    "    mae = mean_absolute_error(valutazione_df[\"rating\"], valutazione_df[\"predicted_rating\"])\n",
    "\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Lista per salvare i risultati\n",
    "    risultati = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # Binarizzazione in base alla soglia\n",
    "        valutazione_df[\"true_label\"] = (valutazione_df[\"rating\"] >= threshold).astype(int)\n",
    "        valutazione_df[\"predicted_label\"] = (valutazione_df[\"predicted_rating\"] >= threshold).astype(int)\n",
    "\n",
    "        # Calcolo metriche di classificazione\n",
    "        accuracy = accuracy_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"])\n",
    "        precision = precision_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"], zero_division=0)\n",
    "        recall = recall_score(valutazione_df[\"true_label\"], valutazione_df[\"predicted_label\"], zero_division=0)\n",
    "\n",
    "        # Stampa risultati\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(\"\")\n",
    "\n",
    "        # Salva risultati in lista\n",
    "        risultati.append({\n",
    "            \"threshold\": threshold,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(risultati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c3bd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0486\n",
      "MAE: 0.7773\n",
      "\n",
      "Threshold: 2\n",
      "Accuracy: 0.9425\n",
      "Precision: 0.9435\n",
      "Recall: 0.9988\n",
      "\n",
      "Threshold: 3\n",
      "Accuracy: 0.8319\n",
      "Precision: 0.8392\n",
      "Recall: 0.9854\n",
      "\n",
      "Threshold: 4.0\n",
      "Accuracy: 0.6487\n",
      "Precision: 0.6846\n",
      "Recall: 0.6816\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.942521</td>\n",
       "      <td>0.943490</td>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.985438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.648742</td>\n",
       "      <td>0.684569</td>\n",
       "      <td>0.681578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy  precision    recall\n",
       "0        2.0  0.942521   0.943490  0.998848\n",
       "1        3.0  0.831875   0.839216  0.985438\n",
       "2        4.0  0.648742   0.684569  0.681578"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [2, 3, 4.0]\n",
    "# Valutazione delle predizioni con le metriche di classificazione per la Similarità Coseno\n",
    "evaluate_ratings(ratings_test, prediction_df, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da02cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_ap_multi_k(ratings_test, prediction_df, k_values=[5], rel_thresholds=[4]):\n",
    "    # Unione dei dataframe test e predizioni\n",
    "    valutazione_df = ratings_test.merge(prediction_df, on=[\"user_id\", \"movie_id\"], how=\"inner\")\n",
    "    all_metrics = []\n",
    "\n",
    "    for rel_threshold in rel_thresholds:\n",
    "        for k in k_values:\n",
    "            for user_id, group in valutazione_df.groupby('user_id'):\n",
    "                # Ordinare per predicted_rating decrescente\n",
    "                group_sorted = group.sort_values('predicted_rating', ascending=False)\n",
    "\n",
    "                # Rilevanti reali (ground truth)\n",
    "                relevant_items = set(group[group['rating'] >= rel_threshold]['movie_id'])\n",
    "\n",
    "                # Top-k raccomandati\n",
    "                recommended = group_sorted.head(k)\n",
    "                recommended_ids = list(recommended['movie_id'])\n",
    "\n",
    "                # Precision@k\n",
    "                rel_k = [1 if movie in relevant_items else 0 for movie in recommended_ids]\n",
    "                precision_at_k = sum(rel_k) / k\n",
    "\n",
    "                # Recall@k\n",
    "                recall_at_k = sum(rel_k) / len(relevant_items) if relevant_items else 0.0\n",
    "\n",
    "                # Average Precision@k (AP@k)\n",
    "                num_hits = 0\n",
    "                sum_precisions = 0.0\n",
    "                for i, hit in enumerate(rel_k):\n",
    "                    if hit:\n",
    "                        num_hits += 1\n",
    "                        sum_precisions += num_hits / (i + 1)\n",
    "                ap_at_k = sum_precisions / len(relevant_items) if relevant_items else 0.0\n",
    "\n",
    "                all_metrics.append({\n",
    "                    'user_id': user_id,\n",
    "                    'k': k,\n",
    "                    'rel_threshold': rel_threshold,\n",
    "                    'precision@k': precision_at_k,\n",
    "                    'recall@k': recall_at_k,\n",
    "                    'ap@k': ap_at_k\n",
    "                })\n",
    "\n",
    "    # Tutti i risultati\n",
    "    results_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "    # MAP@k per ogni combinazione di k e soglia\n",
    "    mapk_summary = (\n",
    "        results_df.groupby(['k', 'rel_threshold'])['ap@k']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'ap@k': 'MAP@k'})\n",
    "    )\n",
    "\n",
    "    return results_df, mapk_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400efaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k per ogni combinazione di k e soglia:\n",
      "    k  rel_threshold     MAP@k\n",
      "0   5              3  0.306373\n",
      "1   5              4  0.257157\n",
      "2  10              3  0.495778\n",
      "3  10              4  0.397778\n",
      "4  15              3  0.596231\n",
      "5  15              4  0.469255\n",
      "6  20              3  0.656256\n",
      "7  20              4  0.512089\n"
     ]
    }
   ],
   "source": [
    "k_list = [5, 10, 15, 20]\n",
    "threshold_list = [3, 4]\n",
    "\n",
    "risultati_utenti, mapk = precision_recall_ap_multi_k(ratings_test, prediction_df, k_list, threshold_list)\n",
    "risultati_utenti.head()\n",
    "\n",
    "print(\"MAP@k per ogni combinazione di k e soglia:\")\n",
    "print(mapk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
